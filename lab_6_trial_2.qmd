---
title: "Lab 6 github"
author: "Lily Heidger"
format: 
  html:
    embed-resources: true
    warnings: false
    messages: false
editor: source
---

```{r}
library(tidyr)
library(dplyr)
library(tidyverse)
library(kableExtra)
library(knitr)
```


## 1. The following anonymized data show the midterm and final exam grades (%) for eight students. The partial ANOVA table provides sum of squares and mean squares. What is the repeatability of grade performance?

### a. Calculate sA2 from the mean squares and the sample size. What variance component does this quantity estimate? 
22.1
variability of mean across groups, used to estimate population variability
```{r}
grades <- data.frame(individual = c(1,2,3,4,5,6,7,8), midterm = c(78,84,94,82,58,62,81,80), final = c(81,65,75,62,60,86,92,89))

anova_table <- data.frame(source = c("individual", "error", "total"), sum_of_squares = c(1145.94, 956.5, 2102.44), df = c(7,8, NA), mean_squares = c(163.71, 119.56, NA))



SA2 <- (163.71 - 119.56) / 2
```

### b. Calculate the repeatability using sA2 and MSerror. 
0.156
```{r}
repeata <- SA2 / (SA2 + 119.56) 
```

### c. Interpret the repeatability you just calculated. What fraction of the variance among test scores is estimated to reflect true differences among students in performance, and what fraction is measurement variance from test to test within students?
16% of total variance is true differences in student performance
remaining is due to test difficulty variation. 

### d. What assumptions are you making when estimating repeatability to test scores?
The assumptions are normality of the data, independent random samples, and equal variance. 

## 2. Many humans like the effect of caffeine, but it occurs in plants as a deterrent to herbivory by animals. Caffeine is also found in flower nectar, and nectar is meant as a reward for pollinators, not a deterrent. How does caffeine in nectar affect visitation by pollinators? Singaravelan et al. (2005) set up feeding stations where bees were offered a choice between a control solution with 20% sucrose or a caffeinated solution with 20% sucrose plus some quantity of caffeine. Over the course of the experiment, four different concentrations of caffeine were provided: 50, 100, 150, and 200 ppm. The response variable was the difference between the amount of nectar consumed from the caffeine feeders and that removed from the control feeders at the same station (in grams). Here are the data:
```{r}
nectar <- data.frame(ppm_50 = c(-0.4, 0.34, 0.19, 0.05, -0.14), ppm_100 =  c(0.01, -0.39, -0.08, -0.09, -0.31), ppm_150 = c(0.65, 0.53, 0.39, -0.15, 0.46), ppm_200 = c(0.24, 0.44, 0.13, 1.03, 0.05))

nectar_long <- pivot_longer(nectar, 
                            cols = everything(), 
                            names_to = "concentration", 
                            values_to = "response")

# Convert concentration levels to a factor
nectar_long$concentration <- as.factor(gsub("ppm_", "", nectar_long$concentration))
```

## Does the mean amount of nectar taken depend on the concentration of caffeine in the nectar? Carry out ANOVA step by step in the following subsections:

### a. State the null and alternate hypotheses appropriate to this question.
H0: the means of all groups are the same
HA: at least 1 mean is different

### b. Calculate the following summary statistics for each group: sample size, sample mean, sample standard deviation.
The sample size is for each group is 5. 
The sample means are 0.008, -0.172, 0.376, and 0.378. 
The sample standard deviations are 0.289, 0.169, 0.309, 0.393. 
```{r}
# mean(nectar$ppm_50)
# mean(nectar$ppm_100)
# mean(nectar$ppm_150)
# mean(nectar$ppm_200)
# 
# sd(nectar$ppm_50)
# sd(nectar$ppm_100)
# sd(nectar$ppm_150)
# sd(nectar$ppm_200)
```
### c. What is the mean square error?
The mean square error is 0.0905. 
```{r}
nectar_aov <- aov(response ~ concentration, data = nectar_long)
summary(nectar_aov)

```

### d. How many degrees of freedom are associated with error?
16

### e. Calculate the estimate of the grand mean.
The grand mean is 0.1475
```{r}
sum(nectar_long$response)/20
```

### f. Calculate the group sum of squares.
1.1344
### g. Calculate the group degrees of freedom and the group mean square.
3
### h. What is F for this example?
4.18
### i. Find the P-value for this test?
0.0231
### j. Report your results in an ANOVA table.
```{r}
# Run ANOVA
nectar_aov <- aov(response ~ concentration, data = nectar_long)
aov <- summary(nectar_aov)

fit <- aov(response ~ concentration, data = nectar_long)
summary_fit <- summary(fit)

anova_table <- summary_fit[[1]]  # Assuming the first element is the table we're interested in

anova_df <- as.data.frame(anova_table)


kable_styled <- kable(anova_df, format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

kable_styled
```




## 3. Use the same data as the previous question, and carry out the Tukey-Kramer test to find which pairs of sample means differ from each other. Report your results in a table with the following columns: Group i label, Group j label, difference of sample means for group i and j, standard error, value of test statistic q, critical value of q, and your conclusion about the hypothesis being tested.

```{r}
tukey_result <- TukeyHSD(nectar_aov)
tukey_result

means <- c(0.008, -0.172, 0.376, 0.378)
std_devs <- c(0.289, 0.169, 0.309, 0.393)
n <- 5  # Sample size per group
k <- length(means)  # Number of groups
N <- n * k  # Total number of observations

MSE <- sum(std_devs^2) / k

alpha <- 0.05
df_error <- N - k
critical_q <- qtukey(1 - alpha, k, df_error)
critical_q

#kable(data.frame(Group_i = ))
```
The mean of group 100 is significantly different than groups 150 and 200. 

## 4. Assume that an analysis of variance is conducted for a study where there are N = 50 observations and k = 5 categories. Fill in the blanks in the following ANOVA table:

### With alpha = 0.05, what is your conclusion regarding the null hypothesis that the means of the categories are equal?
Our F-statistic is 2.62 and our critical value is 2.579. Since F is larger than our critical value, we reject the null hypothesis in favor of the alternative that at least one group's mean is different. 

| Source  |  SS  |   df  |   MS   |   F   |
|:-------:|:----:|:-----:|:------:|:-----:|
|  Group  | 465.2|   4   | 116.3  | 2.62  |
|  Error  | 2000 |  45   |  44.4  |       |
|  Total  |2465.2|  49   |        |       |

## 5. A study classifies 72 observations into nine groups, with eight observations in each group. The study finds that the variance among the 72 observations is 803. Complete the following ANOVA table:

### What do you conclude about the hypothesis that the means of all groups are equal? Assume alpha = 0.05. What can you conclude about the P-value? 
Our F-statistic is 0.92 and our critical value is 2.089. Since F is not larger than our critical value, we fail to reject the null hypothesis that the means are the same.

| Source  |  SS  |   df  |   MS   |   F   |
|:-------:|:----:|:-----:|:------:|:-----:|
|  Group  | 6000 |   8   |  750   | 0.92  |
|  Error  | 51392|  63   |  815.7 |       |
|  Total  | 57392|  71   |        |       |

## 6. Use the Kruskal-Wallis test (with alpha = 0.05) to determine whether you should reject the null hypothesis that the means of the four columns of data are equal:
Fail to reject the null in favor of the alternative that the means are the same. 
```{r}
data <- data.frame(
  Col1 = c(23.1, 13.3, 15.6, 1.2),
  Col2 = c(43.1, 10.2, 16.2, 0.2),
  Col3 = c(56.5, 32.1, 43.3, 24.4),
  Col4 = c(10002.3, 54.4, 8.7, 54.4)
)

data

data_long <- pivot_longer(data, cols = everything(), names_to = "Group", values_to = "Value")

kruskal.test(Value ~ Group, data = data_long)

```
## 7. Huey and Dunham (1987) measured the running speed of fence lizards in Big Bend National Park in Texas. Individual lizards were placed in a 2.3-meter raceway, where their running speeds were measured. Lizards were then tagged and released. The researchers returned to the park the following year, captured many of the same lizards again, and measured their sprint speed in the same way as previously. The pair of measurements for 34 individual lizards is as follows. With these data, calculate the repeatability of the running speed, and what does this metric measure?
The repeatability is 0.88, a high value indicating that the data are consistent in their variance. Any large variations likely due to error or environmental variation. 

```{r}
# Creating the data frame
lizard_data <- data.frame(
  LizardID = c(1:34),
  SprintSpeed1 = c(1.43, 1.56, 1.64, 2.13, 1.96, 1.89, 1.72, 1.80, 1.87, 1.61,
                   1.60, 1.71, 1.83, 1.92, 1.90, 2.06, 2.06, 2.28, 2.44, 2.23,
                   2.53, 2.20, 2.16, 2.25, 2.42, 2.61, 2.62, 3.09, 2.13, 2.44,
                   2.76, 2.96, 3.13, 3.27),
  SprintSpeed2 = c(1.37, 1.30, 1.36, 1.54, 1.82, 1.79, 1.72, 1.80, 1.87, 1.88,
                   1.98, 2.08, 2.16, 2.08, 2.01, 2.03, 1.97, 2.05, 1.92, 2.12,
                   2.11, 2.22, 2.27, 2.39, 2.33, 2.33, 2.39, 2.17, 2.54, 2.63,
                   2.69, 2.64, 2.81, 2.88)
)

lizard_data$mean_speed <- rowMeans(lizard_data[, c("SprintSpeed1", "SprintSpeed2")])

total_variance <- var(c(lizard_data$SprintSpeed1, lizard_data$SprintSpeed2))

within_variance <- mean((lizard_data$SprintSpeed1 - lizard_data$mean_speed)^2 + 
                        (lizard_data$SprintSpeed2 - lizard_data$mean_speed)^2) / 2

among_variance <- total_variance - within_variance

repeatability <- among_variance / total_variance
repeatability

```
## 8. In a study of hyena laughter, or “giggling”, Mathevon et al. (2010) asked whether sound spectral properties of hyenas’ giggles are associated with age. The accompanying data show the giggle fundamental frequency (in Hz) and the age (in years) of 16 hyenas. What is the correlation coefficient in the data, and what is most-plausible range of values for the population correlation?

```{r}
hyena <- data.frame(
  Age_years = c(2, 2, 2, 6, 9, 10, 13, 10, 14, 14, 12, 7, 11, 11, 14, 20),
  Fundamental_frequency_Hz = c(840, 670, 580, 470, 540, 660, 510, 520, 500, 480, 400, 650, 460, 500, 580, 500)
)
```

### a. . Plot the fundamental frequency as a function of the age. Does it suggest a positive or negative association?
The plot suggests a negative association.
```{r}
ggplot(hyena, aes(x = Age_years, y = Fundamental_frequency_Hz)) +
  geom_point() +
  theme_minimal() +
  labs(x = "Age (years)", y = "Fundamental Frequency (Hz)",
       title = "Fundamental Frequency as a Function of Age in Hyenas") +
  geom_smooth(method = "lm", se = FALSE, color = "blue") # Adds a linear regression line without standard error

```

### b. Calculate the sum of squares for age.
The sum of squares for age is 380.4375. 
```{r}
mean_age <- mean(hyena$Age_years)
deviations <- hyena$Age_years - mean_age

squared_deviations <- deviations^2

sum_of_squares_age <- sum(squared_deviations)

sum_of_squares_age
```

### c. Calculate the sum of squares for fundamental frequency.
The sum of squares for fundamental frequency is 174175. 
```{r}
mean_freq <- mean(hyena$Fundamental_frequency_Hz)
deviations <- hyena$Fundamental_frequency_Hz - mean_freq

squared_deviations <- deviations^2

sum_of_squares_freq <- sum(squared_deviations)

sum_of_squares_freq
```

### d. Calculate the sum of products between age and frequency.
The sum of products is 82040. 
```{r}
sum(hyena$Age_years * hyena$Fundamental_frequency_Hz)

```

### e. Compute the correlation coefficient, r.
The correlation coefficient is -0.601798. 
```{r}
correlation_coefficient <- cor(hyena$Age_years, hyena$Fundamental_frequency_Hz)
correlation_coefficient
```

### f. Compute the Fisher’s z-transformation of the correlation coefficient.
Fischer's z-transformation is -0.6959612.
```{r}
r <- correlation_coefficient 

z <- 0.5 * log((1 + r) / (1 - r))

z
```

### g. Calculate the approximate standard error of the z-transformed correlation.
The standard error is 0.2773501. 
```{r}
n <- 16

SE_z <- 1 / sqrt(n - 3)
SE_z
```

### h. What is Zcrit,the two-tailed critical value of the standard normal distribution corresponding to alpha = 0.05?
The value of zcrit is  1.959964. 
```{r}
# Find the critical value for a two-tailed test with alpha = 0.05
Z_crit <- qnorm(0.975) # You can also use 1 - (0.025) which is 0.975

# Print the critical value
Z_crit

```

### i. Calculate the lower and upper bounds of the 95% confidence interval for zeta, the ztransformed population correlation.
The values are [-1.959964, 1.959964].
```{r}
Z_crit_lower <- qnorm(0.025)

Z_crit_upper <- qnorm(0.975)

Z_crit_lower
Z_crit_upper

```

### j. Transform the lower and upper bounds of the confidence interval of zeta, yielding the 95% confidence interval for the population correlation coefficient.
The values are [-0.8453293, -0.1511968]. 
```{r}

alpha <- 0.05
Z_crit <- qnorm(1 - alpha / 2) # Two-tailed critical value
z_L <- z - Z_crit * SE_z # Lower bound
z_U <- z + Z_crit * SE_z # Upper bound

# Transform back to get the confidence interval for r
r_L <- (exp(2 * z_L) - 1) / (exp(2 * z_L) + 1)
r_U <- (exp(2 * z_U) - 1) / (exp(2 * z_U) + 1)

# Print the confidence interval for r
r_L
r_U

```
## 9. Use the same data shown in problem 1. Test whether there is a correlation in the population between giggle fundamental frequency and age.
### a. State the null and alternative hypotheses.
### b. Calculate the standard error of the sample correlation r.
### c. Calculate the t-statistic.
### d. What is the sample size? What are the degrees of freedom?
### e. Obtain the critical value of t corresponding to alpha = 0.05.
### f. What is the conclusion from the test?


## 10. . As human populations become more urban from prehistory to the present, disease transmission between people likely increased. Over time, this might have led to the evolution of enhanced resistance to certain diseases in settled human populations. For example, a mutation in a human gene causes resistance to tuberculosis. Barnes et al. (2011) examined the frequency of the resistant gene in different towns and villages in Europe and Asia and compared it to how long humans had been settled in the site (“duration of settlement”). If settlement led to the evolution of greater resistance to tuberculosis, there should be a positive association between the frequency of resistant gene and the duration of settlement. The data are below. Use the Spearman’s correlation to test an association between these variables.

```{r}
gene_data <- data.frame(
  Duration_years = c(8010, 5260, 4735, 4010, 3710, 2810, 2730, 2310, 2110, 1955,
                     1910, 1300, 378, 194, 130, 110, 91),
  Gene_frequency = c(0.990, 1.000, 0.948, 0.885, 0.947, 0.854, 1.000, 0.769,
                     0.956, 0.979, 0.865, 0.922, 0.821, 0.842, 0.734, 0.766, 0.772)
)



```

### a. Rank duration from low to high.
### b. Rank gene frequency from low to high, assigning midranks to ties.
### c. Calculate the sum of squares for the ranks of duration, gene frequency, and the sum of products.
### d. Compute the Spearman’s correlation coefficient.
### e. What is the sample size?
### f. State the null and alternate hypotheses.
### g. Obtain the critical value for the Spearman’s correlation corresponding to  = 0.05.
### h. Draw the appropriate conclusion.

## 11. . Men’s faces have higher width-to-height ratios than women’s, on average. This turns out to reflect a difference in testosterone expression. Testosterone is also known to predict aggressive behavior. Does face shape predict aggression? To test this, Carré and McCormick (2008) compared the face width-to-height ratio of 21 university hockey players with the average number of penalty minutes awarded per game for aggressive infractions like fighting or cross-checking. Their data are below. Calculate the equation for the line that best predicts penalty minutes from face width-to-height ratios.
```{r}
hockey_data <- data.frame(
  Face_Width_Height = c(1.59, 1.67, 1.65, 1.72, 1.79, 1.77, 1.74, 1.74, 1.77, 1.78, 
                        1.76, 1.81, 1.83, 1.83, 1.84, 1.87, 1.92, 1.95, 1.98, 1.99, 2.07),
  Penalty_Minutes_Per_Game = c(0.44, 1.43, 1.57, 0.14, 0.27, 0.35, 0.85, 1.13, 1.47, 1.51, 
                               1.99, 1.06, 1.20, 1.23, 0.80, 2.53, 1.23, 1.10, 1.61, 1.95, 2.95)
)


```

### a. Plot the data in a scatter plot.
### b. Examine the graph. Based on this graph, do the assumptions of linear regression appear to be met?
### c. Calculate the means of the two variables.
### d. How steeply does the number of penalty minutes increase per unit increase in face ratio? Calculate the estimate of the regression slope. Double check that the sign of the slope matches your impression from the scatter plot.
### e. Calculate the estimate of the intercept from the variable means and your estimate of regression slope.
### f. Write the result in the form of an equation for the line. Add this line to graph in part (a).



## 12. How uncertain is our estimate from the previous analysis? Using the face ratio and hockey aggressive penalty data, calculate the standard error and confidence interval of the slope of the linear regression.
### a. Calculate the total sum of squares for the response/dependent variable, penalty minutes.
### b. Calculate the residual mean square using the total sum of square for Y, and the sum of products, and the slope b.
### c. Calculate the standard error of b.
### d. How many degrees of freedom does this analysis of the slope have?
### e. Find the two-tailed critical t-value for a 95% confidence interval for the appropriate df.
### f. Calculate the confidence interval of the population regression slope.



## 13. Can the above relationship be explained by chance? Using the same data as problem 4, test the null hypothesis that the slope of the regression line is zero.
### a. State the null and alternate hypotheses.
### b. What is the regression slope under the null hypothesis?
### c. Calculate the test statistic t, and the standard error of b.
### d. Find the critical value of t appropriate for the degrees of freedom, at  = 0.05.
### e. Is the absolute value of the t for this test greater than the critical value?
### f. Estimate the P-value for this test, and draw conclusion from this test.
### g. What fraction of the variation in penalty minutes per game is accounted for by face ratio? Calculate the value of R^2.
